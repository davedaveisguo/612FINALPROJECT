{"cells":[{"cell_type":"markdown","source":["## 0. Install Packages"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"38f3da1f-2c54-4b25-93d1-c59410fc56a8"}}},{"cell_type":"code","source":["%sh\npip install nltk\npip install stop-words\npip install pyspellchecker"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a6b19a94-3f49-46d3-85f1-24c9040d89c8"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Requirement already satisfied: nltk in /databricks/python3/lib/python3.8/site-packages (3.6.5)\nRequirement already satisfied: tqdm in /databricks/python3/lib/python3.8/site-packages (from nltk) (4.62.3)\nRequirement already satisfied: click in /databricks/python3/lib/python3.8/site-packages (from nltk) (8.0.3)\nRequirement already satisfied: regex>=2021.8.3 in /databricks/python3/lib/python3.8/site-packages (from nltk) (2021.11.10)\nRequirement already satisfied: joblib in /databricks/python3/lib/python3.8/site-packages (from nltk) (1.0.1)\nRequirement already satisfied: stop-words in /databricks/python3/lib/python3.8/site-packages (2018.7.23)\nRequirement already satisfied: pyspellchecker in /databricks/python3/lib/python3.8/site-packages (0.6.2)\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Requirement already satisfied: nltk in /databricks/python3/lib/python3.8/site-packages (3.6.5)\nRequirement already satisfied: tqdm in /databricks/python3/lib/python3.8/site-packages (from nltk) (4.62.3)\nRequirement already satisfied: click in /databricks/python3/lib/python3.8/site-packages (from nltk) (8.0.3)\nRequirement already satisfied: regex>=2021.8.3 in /databricks/python3/lib/python3.8/site-packages (from nltk) (2021.11.10)\nRequirement already satisfied: joblib in /databricks/python3/lib/python3.8/site-packages (from nltk) (1.0.1)\nRequirement already satisfied: stop-words in /databricks/python3/lib/python3.8/site-packages (2018.7.23)\nRequirement already satisfied: pyspellchecker in /databricks/python3/lib/python3.8/site-packages (0.6.2)\n"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["## 1. Load Original Data"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6786586f-7da7-4eb3-a69a-5e78f40bf496"}}},{"cell_type":"code","source":["from sklearn.datasets import fetch_20newsgroups\nimport pandas as pd\nimport numpy as np\nimport re\nfrom pyspark.sql import SQLContext\n\ncategories = ['rec.autos', 'rec.sport.baseball', 'comp.graphics', 'comp.sys.mac.hardware', \n              'sci.space', 'sci.crypt', 'talk.politics.guns', 'talk.religion.misc']\nnewsgroup = fetch_20newsgroups(subset='train',categories= categories , shuffle=True, random_state=42)\n\ndf_news = pd.DataFrame(data=newsgroup.data, columns=['news']) \ndf_news = df_news.replace(re.compile(r\"From: \\S*@\\S*\\s?\"),\"\")\ndf_news = df_news.replace(re.compile('\\s+'),\" \")\ndf_news = df_news.replace(re.compile(\"\\'\"),\"\")\n\ndf_target = pd.DataFrame(data=newsgroup.target, columns=['target'])\ndf_target['target']=df_target.target.astype('int64')\ndf_binary_labels = pd.DataFrame(np.where (df_target < 10, 0, 1), columns=['Binary Label'])\n\nsqlContext = SQLContext(sc)\ndf_newsgroup = sqlContext.createDataFrame(pd.concat([df_news, df_target, df_binary_labels], axis=1))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"76b7b165-7c1a-4f34-a415-2234591295ba"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## 2. Pipeline"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f5406831-fd9c-410b-9017-0d161c64d6ea"}}},{"cell_type":"code","source":["from pyspark.ml.feature import RegexTokenizer, StopWordsRemover\nfrom pyspark.ml.feature import Tokenizer, HashingTF, IDF, StringIndexer\nfrom pyspark.ml.classification import DecisionTreeClassifier\nfrom pyspark.ml import Pipeline\n\n\nregexTokenizer = RegexTokenizer(inputCol=\"news\", outputCol=\"news_words\", pattern=\"\\\\W\")\nadd_stopwords = [\"http\",\"https\",\"amp\",\"rt\",\"t\",\"c\",\"the\",\"subject\",\"re\",'.',',','', 'i i','?','\\'\\'',\"''\",'y','*','out','==','df','e.g.','\\'m','\\[',\"'m\",':', ')', '(','n\\'t', '\\'','``','``','\\'s', 'https://','-'] \nstopwordsRemover = StopWordsRemover(inputCol=regexTokenizer.getOutputCol(), outputCol=\"filtered\").setStopWords(add_stopwords)\nhashingTF = HashingTF(inputCol=stopwordsRemover.getOutputCol(), outputCol=\"rawFeatures\", numFeatures=10000)\nidf = IDF(inputCol=hashingTF.getOutputCol(), outputCol=\"features\", minDocFreq=5) #minDocFreq: remove sparse terms\nstring_indexer = StringIndexer(inputCol = \"target\", outputCol = \"target_indexed\")\n\npipeline = Pipeline(stages=[regexTokenizer, stopwordsRemover, hashingTF, idf, string_indexer])\npipelineFit = pipeline.fit(df_newsgroup)\ndataset = pipelineFit.transform(df_newsgroup)\n(trainingData, testData) = dataset.randomSplit([0.7, 0.3], seed = 100)\n\ndtc = DecisionTreeClassifier(labelCol=string_indexer.getOutputCol(), maxDepth=10)\ndtc_mod = dtc.fit(trainingData)\npredictions = dtc_mod.transform(testData)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ad0fc6b2-eb39-4fb5-a34b-5b95ab291724"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## 3. Evaluate Decision Tree Classifier Model"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8ceb0b67-d451-492d-8e4b-158003aa5a9a"}}},{"cell_type":"code","source":["from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n\nevaluator = MulticlassClassificationEvaluator(labelCol=\"target_indexed\", predictionCol=\"prediction\")\nscore = evaluator.evaluate(predictions)\nprint(\"score = %s\" % (score) + \"\\n\")\n\nprint (\"accuracy: \" + str (evaluator.evaluate(predictions, {evaluator.metricName: \"accuracy\"})) )\nprint (\"weightedPrecision: \" + str (evaluator.evaluate(predictions, {evaluator.metricName: \"weightedPrecision\"})) )\nprint (\"weightedRecall: \" + str (evaluator.evaluate(predictions, {evaluator.metricName: \"weightedRecall\"}))  )\nprint (\"weightedTruePositiveRate: \" + str (evaluator.evaluate(predictions, {evaluator.metricName: \"weightedTruePositiveRate\"})) )\nprint (\"weightedFalsePositiveRate: \" + str (evaluator.evaluate(predictions, {evaluator.metricName: \"weightedFalsePositiveRate\"})) )\nprint (\"weightedFMeasure: \" + str (evaluator.evaluate(predictions, {evaluator.metricName: \"weightedFMeasure\"})) )\nprint (\"truePositiveRateByLabel: \" + str (evaluator.evaluate(predictions, {evaluator.metricName: \"truePositiveRateByLabel\"})))\nprint (\"falsePositiveRateByLabel: \" + str (evaluator.evaluate(predictions, {evaluator.metricName: \"falsePositiveRateByLabel\"})) )\nprint (\"precisionByLabel: \" + str (evaluator.evaluate(predictions, {evaluator.metricName: \"precisionByLabel\"})) )\nprint (\"recallByLabel: \" + str (evaluator.evaluate(predictions, {evaluator.metricName: \"recallByLabel\"})) )\nprint (\"fMeasureByLabel: \" + str (evaluator.evaluate(predictions, {evaluator.metricName: \"fMeasureByLabel\"})) )\nprint (\"hammingLoss: \" + str (evaluator.evaluate(predictions, {evaluator.metricName: \"hammingLoss\"})) )"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"41257130-38d7-4cfa-93cf-9817087f8e6f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Score = 0.5799297896381792\n\naccuracy: 0.5524278676988037\nweightedPrecision: 0.7573661887631485\nweightedRecall: 0.5524278676988037\nweightedTruePositiveRate: 0.5524278676988037\nweightedFalsePositiveRate: 0.06976096138084037\nweightedFMeasure: 0.5799297896381792\ntruePositiveRateByLabel: 0.9536082474226805\nfalsePositiveRateByLabel: 0.42461287693561534\nprecisionByLabel: 0.26203966005665724\nrecallByLabel: 0.9536082474226805\nfMeasureByLabel: 0.41111111111111115\nhammingLoss: 0.44757213230119636\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Score = 0.5799297896381792\n\naccuracy: 0.5524278676988037\nweightedPrecision: 0.7573661887631485\nweightedRecall: 0.5524278676988037\nweightedTruePositiveRate: 0.5524278676988037\nweightedFalsePositiveRate: 0.06976096138084037\nweightedFMeasure: 0.5799297896381792\ntruePositiveRateByLabel: 0.9536082474226805\nfalsePositiveRateByLabel: 0.42461287693561534\nprecisionByLabel: 0.26203966005665724\nrecallByLabel: 0.9536082474226805\nfMeasureByLabel: 0.41111111111111115\nhammingLoss: 0.44757213230119636\n"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["## 4. Cross-Validation and Hyperparameter Tuning"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0b5076f5-04d6-456b-bb50-e8c42f26d850"}}},{"cell_type":"code","source":["from pyspark.ml.tuning import ParamGridBuilder\nfrom pyspark.ml.tuning import CrossValidator\n\ntrainingData1 = trainingData.drop(\"news_words\",\"news_tf\",\"news_tfidf\",\"rawPrediction\",\"probability\",\"prediction\",\"filtered\",\"rawFeatures\",\"CrossValidator_2b30ebf36fbb_rand\")\ntestData1 = testData.drop(\"news_words\",\"news_tf\",\"news_tfidf\",\"rawPrediction\",\"probability\",\"prediction\",\"filtered\",\"rawFeatures\",\"CrossValidator_2b30ebf36fbb_rand\")\ntrainingData1.show(5)\n\n# Grid for DecisionTreeClassifier\ngrid = (ParamGridBuilder().baseOn([evaluator.metricName, 'precision']) \\\n        .addGrid(dtc.maxDepth, [2, 5, 10, 20, 30]) \\\n        .addGrid(dtc.maxBins, [10, 20, 40, 80, 100]) \\\n        .build()) \\\n\n\n# Instantiation of a CrossValidator\ncv = CrossValidator(estimator=dtc, estimatorParamMaps=grid, evaluator=evaluator, numFolds=3)\n\n# Transform the data and train the classifier on the training set\ncv_model = cv.fit(trainingData1)\n\n# Transform the data and perform predictions on the test set\ndf_test_pred1 = cv_model.transform(testData1)\n\n# Evaluate the predictions done on the test set\nevaluator.evaluate(df_test_pred1)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6ab37513-45ba-49c6-be34-5229cf7281fd"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+--------------------+------+------------+--------------------+--------------+\n|                news|target|Binary Label|            features|target_indexed|\n+--------------------+------+------------+--------------------+--------------+\n| (Peter van der V...|     0|           0|(10000,[42,66,120...|           4.0|\n|( Nikan B Firoozy...|     5|           0|(10000,[55,222,26...|           3.0|\n|( Phil Mueller ) ...|     2|           0|(10000,[15,78,207...|           2.0|\n|(1016/2EF221) Sub...|     4|           0|(10000,[24,42,66,...|           1.0|\n|(A.Lizard) Subjec...|     7|           0|(10000,[31,425,44...|           7.0|\n+--------------------+------+------------+--------------------+--------------+\nonly showing top 5 rows\n\n/databricks/spark/python/pyspark/ml/util.py:847: UserWarning: MLlib could not reach the MLflow server at tracking URI: databricks\nException: You haven't configured the CLI yet! Please configure by entering `/databricks/python_shell/scripts/db_ipykernel_launcher.py configure`\n  warnings.warn(\nOut[35]: 0.7273382709823668","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+--------------------+------+------------+--------------------+--------------+\n|                news|target|Binary Label|            features|target_indexed|\n+--------------------+------+------------+--------------------+--------------+\n| (Peter van der V...|     0|           0|(10000,[42,66,120...|           4.0|\n|( Nikan B Firoozy...|     5|           0|(10000,[55,222,26...|           3.0|\n|( Phil Mueller ) ...|     2|           0|(10000,[15,78,207...|           2.0|\n|(1016/2EF221) Sub...|     4|           0|(10000,[24,42,66,...|           1.0|\n|(A.Lizard) Subjec...|     7|           0|(10000,[31,425,44...|           7.0|\n+--------------------+------+------------+--------------------+--------------+\nonly showing top 5 rows\n\n/databricks/spark/python/pyspark/ml/util.py:847: UserWarning: MLlib could not reach the MLflow server at tracking URI: databricks\nException: You haven't configured the CLI yet! Please configure by entering `/databricks/python_shell/scripts/db_ipykernel_launcher.py configure`\n  warnings.warn(\nOut[35]: 0.7273382709823668"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["## 5. Best Parameters and Metric Scores"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"26e62378-e8e4-49d9-bdb3-286c895939d9"}}},{"cell_type":"code","source":["bestModel = cv_model.bestModel\n\nprint ('Best Param (maxDepth): ', bestModel._java_obj.getMaxDepth())\nprint ('Best Param (maxBins): ', bestModel._java_obj.getMaxBins())\n\nprint (\"accuracy: \" + str (evaluator.evaluate(df_test_pred1, {evaluator.metricName: \"accuracy\"})) )\nprint (\"weightedPrecision: \" + str (evaluator.evaluate(df_test_pred1, {evaluator.metricName: \"weightedPrecision\"})) )\nprint (\"weightedRecall: \" + str (evaluator.evaluate(df_test_pred1, {evaluator.metricName: \"weightedRecall\"}))  )\nprint (\"weightedTruePositiveRate: \" + str (evaluator.evaluate(df_test_pred1, {evaluator.metricName: \"weightedTruePositiveRate\"})) )\nprint (\"weightedFalsePositiveRate: \" + str (evaluator.evaluate(df_test_pred1, {evaluator.metricName: \"weightedFalsePositiveRate\"})) )\nprint (\"weightedFMeasure: \" + str (evaluator.evaluate(df_test_pred1, {evaluator.metricName: \"weightedFMeasure\"})) )\nprint (\"truePositiveRateByLabel: \" + str (evaluator.evaluate(df_test_pred1, {evaluator.metricName: \"truePositiveRateByLabel\"})))\nprint (\"falsePositiveRateByLabel: \" + str (evaluator.evaluate(df_test_pred1, {evaluator.metricName: \"falsePositiveRateByLabel\"})) )\nprint (\"precisionByLabel: \" + str (evaluator.evaluate(df_test_pred1, {evaluator.metricName: \"precisionByLabel\"})) )\nprint (\"recallByLabel: \" + str (evaluator.evaluate(df_test_pred1, {evaluator.metricName: \"recallByLabel\"})) )\nprint (\"fMeasureByLabel: \" + str (evaluator.evaluate(df_test_pred1, {evaluator.metricName: \"fMeasureByLabel\"})) )\nprint (\"hammingLoss: \" + str (evaluator.evaluate(df_test_pred1, {evaluator.metricName: \"hammingLoss\"})) )"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"14a3aa03-ecb8-4082-a281-6b9bb00b91e7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Best Param (maxDepth):  30\nBest Param (maxBins):  10\naccuracy: 0.7107670654468684\nweightedPrecision: 0.7790471484546007\nweightedRecall: 0.7107670654468683\nweightedTruePositiveRate: 0.7107670654468683\nweightedFalsePositiveRate: 0.04280315820820069\nweightedFMeasure: 0.7273382709823668\ntruePositiveRateByLabel: 0.6855670103092784\nfalsePositiveRateByLabel: 0.022004889975550123\nprecisionByLabel: 0.83125\nrecallByLabel: 0.6855670103092784\nfMeasureByLabel: 0.751412429378531\nhammingLoss: 0.2892329345531316\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Best Param (maxDepth):  30\nBest Param (maxBins):  10\naccuracy: 0.7107670654468684\nweightedPrecision: 0.7790471484546007\nweightedRecall: 0.7107670654468683\nweightedTruePositiveRate: 0.7107670654468683\nweightedFalsePositiveRate: 0.04280315820820069\nweightedFMeasure: 0.7273382709823668\ntruePositiveRateByLabel: 0.6855670103092784\nfalsePositiveRateByLabel: 0.022004889975550123\nprecisionByLabel: 0.83125\nrecallByLabel: 0.6855670103092784\nfMeasureByLabel: 0.751412429378531\nhammingLoss: 0.2892329345531316\n"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7a3d1ee1-2413-446a-8742-4733d39e29a0"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"ENSF 612 Term Proj (DecisionTree Original only)","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":2551240899384485}},"nbformat":4,"nbformat_minor":0}
