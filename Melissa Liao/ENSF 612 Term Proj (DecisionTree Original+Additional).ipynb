{"cells":[{"cell_type":"markdown","source":["## 0. Install Packages"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"38f3da1f-2c54-4b25-93d1-c59410fc56a8"}}},{"cell_type":"code","source":["%sh\npip install nltk\npip install stop-words\npip install pyspellchecker"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a6b19a94-3f49-46d3-85f1-24c9040d89c8"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Requirement already satisfied: nltk in /databricks/python3/lib/python3.8/site-packages (3.6.5)\nRequirement already satisfied: tqdm in /databricks/python3/lib/python3.8/site-packages (from nltk) (4.62.3)\nRequirement already satisfied: click in /databricks/python3/lib/python3.8/site-packages (from nltk) (8.0.3)\nRequirement already satisfied: regex>=2021.8.3 in /databricks/python3/lib/python3.8/site-packages (from nltk) (2021.11.10)\nRequirement already satisfied: joblib in /databricks/python3/lib/python3.8/site-packages (from nltk) (1.0.1)\nRequirement already satisfied: stop-words in /databricks/python3/lib/python3.8/site-packages (2018.7.23)\nRequirement already satisfied: pyspellchecker in /databricks/python3/lib/python3.8/site-packages (0.6.2)\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Requirement already satisfied: nltk in /databricks/python3/lib/python3.8/site-packages (3.6.5)\nRequirement already satisfied: tqdm in /databricks/python3/lib/python3.8/site-packages (from nltk) (4.62.3)\nRequirement already satisfied: click in /databricks/python3/lib/python3.8/site-packages (from nltk) (8.0.3)\nRequirement already satisfied: regex>=2021.8.3 in /databricks/python3/lib/python3.8/site-packages (from nltk) (2021.11.10)\nRequirement already satisfied: joblib in /databricks/python3/lib/python3.8/site-packages (from nltk) (1.0.1)\nRequirement already satisfied: stop-words in /databricks/python3/lib/python3.8/site-packages (2018.7.23)\nRequirement already satisfied: pyspellchecker in /databricks/python3/lib/python3.8/site-packages (0.6.2)\n"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["## 1.1. Load Additional Labeled Data"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6fef7f24-305e-426a-b827-6ec91dca263a"}}},{"cell_type":"code","source":["import pandas as pd\nimport numpy as np\n# File location and type\nfile_location = \"/FileStore/tables/additional.csv\"\nfile_type = \"csv\"\n\n# CSV options\ninfer_schema = \"false\"\nfirst_row_is_header = \"false\"\ndelimiter = \",\"\n\ndf = spark.read.format(file_type).option(\"inferSchema\", infer_schema).option(\"header\", \"true\").option(\"sep\", delimiter).load(file_location)\n\npandasDF_news = df.select('news').toPandas()\npandasDF_target = df.select('target').toPandas()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"065a8ba3-3692-4147-80a6-ca891b28cda9"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## 1.2. Load Original Data"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"782199d8-71d2-49b1-87c5-80ac8470ed51"}}},{"cell_type":"code","source":["from sklearn.datasets import fetch_20newsgroups\nimport pandas as pd\nimport numpy as np\nimport re\nfrom pyspark.sql import SQLContext\n\ncategories = ['rec.autos', 'rec.sport.baseball', 'comp.graphics', 'comp.sys.mac.hardware', \n              'sci.space', 'sci.crypt', 'talk.politics.guns', 'talk.religion.misc']\nnewsgroup = fetch_20newsgroups(subset='train',categories= categories , shuffle=True, random_state=42)\n\ndf_news = pd.DataFrame(data=newsgroup.data, columns=['news']) \ndf_news = df_news.append(pandasDF_news, ignore_index=True)\ndf_news = df_news.replace(re.compile(r\"From: \\S*@\\S*\\s?\"),\"\")\ndf_news = df_news.replace(re.compile('\\s+'),\" \")\ndf_news = df_news.replace(re.compile(\"\\'\"),\"\")\n\ndf_target = pd.DataFrame(data=newsgroup.target, columns=['target'])\ndf_target = df_target.append(pandasDF_target, ignore_index=True)\ndf_target['target']=df_target.target.astype('int64')\ndf_binary_labels = pd.DataFrame(np.where (df_target < 10, 0, 1), columns=['Binary Label'])\n\nsqlContext = SQLContext(sc)\ndf_newsgroup = sqlContext.createDataFrame(pd.concat([df_news, df_target, df_binary_labels], axis=1))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"76b7b165-7c1a-4f34-a415-2234591295ba"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## 2. Pipeline"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f5406831-fd9c-410b-9017-0d161c64d6ea"}}},{"cell_type":"code","source":["from pyspark.ml.feature import RegexTokenizer, StopWordsRemover\nfrom pyspark.ml.feature import Tokenizer, HashingTF, IDF, StringIndexer\nfrom pyspark.ml.classification import DecisionTreeClassifier\nfrom pyspark.ml import Pipeline\n\nregexTokenizer = RegexTokenizer(inputCol=\"news\", outputCol=\"news_words\", pattern=\"\\\\W\")\nadd_stopwords = [\"http\",\"https\",\"amp\",\"rt\",\"t\",\"c\",\"the\",\"subject\",\"re\",'.',',','', 'i i','?','\\'\\'',\"''\",'y','*','out','==','df','e.g.','\\'m','\\[',\"'m\",':', ')', '(','n\\'t', '\\'','``','``','\\'s', 'https://','-'] \nstopwordsRemover = StopWordsRemover(inputCol=regexTokenizer.getOutputCol(), outputCol=\"filtered\").setStopWords(add_stopwords)\nhashingTF = HashingTF(inputCol=stopwordsRemover.getOutputCol(), outputCol=\"rawFeatures\", numFeatures=10000)\nidf = IDF(inputCol=hashingTF.getOutputCol(), outputCol=\"features\", minDocFreq=5) #minDocFreq: remove sparse terms\nstring_indexer = StringIndexer(inputCol = \"target\", outputCol = \"target_indexed\")\n\npipeline = Pipeline(stages=[regexTokenizer, stopwordsRemover, hashingTF, idf, string_indexer])\npipelineFit = pipeline.fit(df_newsgroup)\ndataset = pipelineFit.transform(df_newsgroup)\n(trainingData, testData) = dataset.randomSplit([0.7, 0.3], seed = 100)\n\ndtc = DecisionTreeClassifier(labelCol=string_indexer.getOutputCol(), maxDepth=10)\ndtc_mod = dtc.fit(trainingData)\npredictions = dtc_mod.transform(testData)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ad0fc6b2-eb39-4fb5-a34b-5b95ab291724"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## 3. Evaluate Decision Tree Classifier Model"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8ceb0b67-d451-492d-8e4b-158003aa5a9a"}}},{"cell_type":"code","source":["from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n\nevaluator = MulticlassClassificationEvaluator(labelCol=\"target_indexed\", predictionCol=\"prediction\")\nscore = evaluator.evaluate(predictions)\nprint(\"score = %s\" % (score) + \"\\n\")\n\nprint (\"accuracy: \" + str (evaluator.evaluate(predictions, {evaluator.metricName: \"accuracy\"})) )\nprint (\"weightedPrecision: \" + str (evaluator.evaluate(predictions, {evaluator.metricName: \"weightedPrecision\"})) )\nprint (\"weightedRecall: \" + str (evaluator.evaluate(predictions, {evaluator.metricName: \"weightedRecall\"}))  )\nprint (\"weightedTruePositiveRate: \" + str (evaluator.evaluate(predictions, {evaluator.metricName: \"weightedTruePositiveRate\"})) )\nprint (\"weightedFalsePositiveRate: \" + str (evaluator.evaluate(predictions, {evaluator.metricName: \"weightedFalsePositiveRate\"})) )\nprint (\"weightedFMeasure: \" + str (evaluator.evaluate(predictions, {evaluator.metricName: \"weightedFMeasure\"})) )\nprint (\"truePositiveRateByLabel: \" + str (evaluator.evaluate(predictions, {evaluator.metricName: \"truePositiveRateByLabel\"})))\nprint (\"falsePositiveRateByLabel: \" + str (evaluator.evaluate(predictions, {evaluator.metricName: \"falsePositiveRateByLabel\"})) )\nprint (\"precisionByLabel: \" + str (evaluator.evaluate(predictions, {evaluator.metricName: \"precisionByLabel\"})) )\nprint (\"recallByLabel: \" + str (evaluator.evaluate(predictions, {evaluator.metricName: \"recallByLabel\"})) )\nprint (\"fMeasureByLabel: \" + str (evaluator.evaluate(predictions, {evaluator.metricName: \"fMeasureByLabel\"})) )\nprint (\"hammingLoss: \" + str (evaluator.evaluate(predictions, {evaluator.metricName: \"hammingLoss\"})) )"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"41257130-38d7-4cfa-93cf-9817087f8e6f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"score = 0.5829143672986536\n\naccuracy: 0.5556213017751479\nweightedPrecision: 0.7346671946678965\nweightedRecall: 0.555621301775148\nweightedTruePositiveRate: 0.555621301775148\nweightedFalsePositiveRate: 0.05878185485447813\nweightedFMeasure: 0.5829143672986536\ntruePositiveRateByLabel: 0.565625\nfalsePositiveRateByLabel: 0.03722627737226277\nprecisionByLabel: 0.7801724137931034\nrecallByLabel: 0.565625\nfMeasureByLabel: 0.6557971014492754\nhammingLoss: 0.4443786982248521\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["score = 0.5829143672986536\n\naccuracy: 0.5556213017751479\nweightedPrecision: 0.7346671946678965\nweightedRecall: 0.555621301775148\nweightedTruePositiveRate: 0.555621301775148\nweightedFalsePositiveRate: 0.05878185485447813\nweightedFMeasure: 0.5829143672986536\ntruePositiveRateByLabel: 0.565625\nfalsePositiveRateByLabel: 0.03722627737226277\nprecisionByLabel: 0.7801724137931034\nrecallByLabel: 0.565625\nfMeasureByLabel: 0.6557971014492754\nhammingLoss: 0.4443786982248521\n"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["## 4. Cross-Validation and Hyperparameter Tuning"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0b5076f5-04d6-456b-bb50-e8c42f26d850"}}},{"cell_type":"code","source":["from pyspark.ml.tuning import ParamGridBuilder\nfrom pyspark.ml.tuning import CrossValidator\n\ntrainingData1 = trainingData.drop(\"news_words\",\"news_tf\",\"news_tfidf\",\"rawPrediction\",\"probability\",\"prediction\",\"filtered\",\"rawFeatures\",\"CrossValidator_2b30ebf36fbb_rand\")\ntestData1 = testData.drop(\"news_words\",\"news_tf\",\"news_tfidf\",\"rawPrediction\",\"probability\",\"prediction\",\"filtered\",\"rawFeatures\",\"CrossValidator_2b30ebf36fbb_rand\")\ntrainingData1.show(5)\n\n# Grid for DecisionTreeClassifier\ngrid = (ParamGridBuilder().baseOn([evaluator.metricName, 'precision']) \\\n        .addGrid(dtc.maxDepth, [2, 5, 10, 20, 30]) \\\n        .addGrid(dtc.maxBins, [10, 20, 40, 80, 100]) \\\n        .build()) \\\n\n\n# Instantiation of a CrossValidator\ncv = CrossValidator(estimator=dtc, estimatorParamMaps=grid, evaluator=evaluator, numFolds=3)\n\n# Transform the data and train the classifier on the training set\ncv_model = cv.fit(trainingData1)\n\n# Transform the data and perform predictions on the test set\ndf_test_pred1 = cv_model.transform(testData1)\n\n# Evaluate the predictions done on the test set\nevaluator.evaluate(df_test_pred1)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6ab37513-45ba-49c6-be34-5229cf7281fd"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+--------------------+------+------------+--------------------+--------------+\n|                news|target|Binary Label|            features|target_indexed|\n+--------------------+------+------------+--------------------+--------------+\n| (Peter van der V...|     0|           0|(10000,[42,66,120...|           5.0|\n|( Nikan B Firoozy...|     5|           0|(10000,[55,222,26...|           4.0|\n|( Phil Mueller ) ...|     2|           0|(10000,[15,78,207...|           1.0|\n|(\"Imaging Club\") ...|     0|           0|(10000,[78,452,48...|           5.0|\n|(\"RWTMS2::MUNIZB\"...|     5|           0|(10000,[66,78,86,...|           4.0|\n+--------------------+------+------------+--------------------+--------------+\nonly showing top 5 rows\n\n/databricks/spark/python/pyspark/ml/util.py:847: UserWarning: MLlib could not reach the MLflow server at tracking URI: databricks\nException: You haven't configured the CLI yet! Please configure by entering `/databricks/python_shell/scripts/db_ipykernel_launcher.py configure`\n  warnings.warn(\nOut[30]: 0.690259126923159","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+--------------------+------+------------+--------------------+--------------+\n|                news|target|Binary Label|            features|target_indexed|\n+--------------------+------+------------+--------------------+--------------+\n| (Peter van der V...|     0|           0|(10000,[42,66,120...|           5.0|\n|( Nikan B Firoozy...|     5|           0|(10000,[55,222,26...|           4.0|\n|( Phil Mueller ) ...|     2|           0|(10000,[15,78,207...|           1.0|\n|(\"Imaging Club\") ...|     0|           0|(10000,[78,452,48...|           5.0|\n|(\"RWTMS2::MUNIZB\"...|     5|           0|(10000,[66,78,86,...|           4.0|\n+--------------------+------+------------+--------------------+--------------+\nonly showing top 5 rows\n\n/databricks/spark/python/pyspark/ml/util.py:847: UserWarning: MLlib could not reach the MLflow server at tracking URI: databricks\nException: You haven't configured the CLI yet! Please configure by entering `/databricks/python_shell/scripts/db_ipykernel_launcher.py configure`\n  warnings.warn(\nOut[30]: 0.690259126923159"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["## 5. Best Parameters and Metric Scores"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"17ce3d44-8f82-4f39-9076-2033f02e190f"}}},{"cell_type":"code","source":["bestModel = cv_model.bestModel\n\nprint ('Best Param (maxDepth): ', bestModel._java_obj.getMaxDepth())\nprint ('Best Param (maxBins): ', bestModel._java_obj.getMaxBins())\n\nprint (\"accuracy: \" + str (evaluator.evaluate(df_test_pred1, {evaluator.metricName: \"accuracy\"})) )\nprint (\"weightedPrecision: \" + str (evaluator.evaluate(df_test_pred1, {evaluator.metricName: \"weightedPrecision\"})) )\nprint (\"weightedRecall: \" + str (evaluator.evaluate(df_test_pred1, {evaluator.metricName: \"weightedRecall\"}))  )\nprint (\"weightedTruePositiveRate: \" + str (evaluator.evaluate(df_test_pred1, {evaluator.metricName: \"weightedTruePositiveRate\"})) )\nprint (\"weightedFalsePositiveRate: \" + str (evaluator.evaluate(df_test_pred1, {evaluator.metricName: \"weightedFalsePositiveRate\"})) )\nprint (\"weightedFMeasure: \" + str (evaluator.evaluate(df_test_pred1, {evaluator.metricName: \"weightedFMeasure\"})) )\nprint (\"truePositiveRateByLabel: \" + str (evaluator.evaluate(df_test_pred1, {evaluator.metricName: \"truePositiveRateByLabel\"})))\nprint (\"falsePositiveRateByLabel: \" + str (evaluator.evaluate(df_test_pred1, {evaluator.metricName: \"falsePositiveRateByLabel\"})) )\nprint (\"precisionByLabel: \" + str (evaluator.evaluate(df_test_pred1, {evaluator.metricName: \"precisionByLabel\"})) )\nprint (\"recallByLabel: \" + str (evaluator.evaluate(df_test_pred1, {evaluator.metricName: \"recallByLabel\"})) )\nprint (\"fMeasureByLabel: \" + str (evaluator.evaluate(df_test_pred1, {evaluator.metricName: \"fMeasureByLabel\"})) )\nprint (\"hammingLoss: \" + str (evaluator.evaluate(df_test_pred1, {evaluator.metricName: \"hammingLoss\"})) )"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"14a3aa03-ecb8-4082-a281-6b9bb00b91e7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Best Param (maxDepth):  30\nBest Param (maxBins):  20\naccuracy: 0.6715976331360947\nweightedPrecision: 0.7508143446549618\nweightedRecall: 0.6715976331360947\nweightedTruePositiveRate: 0.6715976331360947\nweightedFalsePositiveRate: 0.039398178961806814\nweightedFMeasure: 0.690259126923159\ntruePositiveRateByLabel: 0.7375\nfalsePositiveRateByLabel: 0.041605839416058395\nprecisionByLabel: 0.8054607508532423\nrecallByLabel: 0.7375\nfMeasureByLabel: 0.7699836867862969\nhammingLoss: 0.32840236686390534\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Best Param (maxDepth):  30\nBest Param (maxBins):  20\naccuracy: 0.6715976331360947\nweightedPrecision: 0.7508143446549618\nweightedRecall: 0.6715976331360947\nweightedTruePositiveRate: 0.6715976331360947\nweightedFalsePositiveRate: 0.039398178961806814\nweightedFMeasure: 0.690259126923159\ntruePositiveRateByLabel: 0.7375\nfalsePositiveRateByLabel: 0.041605839416058395\nprecisionByLabel: 0.8054607508532423\nrecallByLabel: 0.7375\nfMeasureByLabel: 0.7699836867862969\nhammingLoss: 0.32840236686390534\n"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7a3d1ee1-2413-446a-8742-4733d39e29a0"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"ENSF 612 Term Proj (DecisionTree Original+Additional)","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":372560549255751}},"nbformat":4,"nbformat_minor":0}
