{"cells":[{"cell_type":"markdown","source":["####Install"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"38f3da1f-2c54-4b25-93d1-c59410fc56a8"}}},{"cell_type":"code","source":["%sh\npip install nltk\npip install stop-words\npip install pyspellchecker"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a6b19a94-3f49-46d3-85f1-24c9040d89c8"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Requirement already satisfied: nltk in /databricks/python3/lib/python3.8/site-packages (3.6.5)\nRequirement already satisfied: tqdm in /databricks/python3/lib/python3.8/site-packages (from nltk) (4.62.3)\nRequirement already satisfied: click in /databricks/python3/lib/python3.8/site-packages (from nltk) (8.0.3)\nRequirement already satisfied: regex>=2021.8.3 in /databricks/python3/lib/python3.8/site-packages (from nltk) (2021.11.10)\nRequirement already satisfied: joblib in /databricks/python3/lib/python3.8/site-packages (from nltk) (1.0.1)\nWARNING: You are using pip version 21.0.1; however, version 21.3.1 is available.\nYou should consider upgrading via the '/databricks/python3/bin/python -m pip install --upgrade pip' command.\nRequirement already satisfied: stop-words in /databricks/python3/lib/python3.8/site-packages (2018.7.23)\nWARNING: You are using pip version 21.0.1; however, version 21.3.1 is available.\nYou should consider upgrading via the '/databricks/python3/bin/python -m pip install --upgrade pip' command.\nRequirement already satisfied: pyspellchecker in /databricks/python3/lib/python3.8/site-packages (0.6.2)\nWARNING: You are using pip version 21.0.1; however, version 21.3.1 is available.\nYou should consider upgrading via the '/databricks/python3/bin/python -m pip install --upgrade pip' command.\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Requirement already satisfied: nltk in /databricks/python3/lib/python3.8/site-packages (3.6.5)\nRequirement already satisfied: tqdm in /databricks/python3/lib/python3.8/site-packages (from nltk) (4.62.3)\nRequirement already satisfied: click in /databricks/python3/lib/python3.8/site-packages (from nltk) (8.0.3)\nRequirement already satisfied: regex>=2021.8.3 in /databricks/python3/lib/python3.8/site-packages (from nltk) (2021.11.10)\nRequirement already satisfied: joblib in /databricks/python3/lib/python3.8/site-packages (from nltk) (1.0.1)\nWARNING: You are using pip version 21.0.1; however, version 21.3.1 is available.\nYou should consider upgrading via the '/databricks/python3/bin/python -m pip install --upgrade pip' command.\nRequirement already satisfied: stop-words in /databricks/python3/lib/python3.8/site-packages (2018.7.23)\nWARNING: You are using pip version 21.0.1; however, version 21.3.1 is available.\nYou should consider upgrading via the '/databricks/python3/bin/python -m pip install --upgrade pip' command.\nRequirement already satisfied: pyspellchecker in /databricks/python3/lib/python3.8/site-packages (0.6.2)\nWARNING: You are using pip version 21.0.1; however, version 21.3.1 is available.\nYou should consider upgrading via the '/databricks/python3/bin/python -m pip install --upgrade pip' command.\n"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["####TBD\n\n1. Tokenization into words\n2. Stop words removal\n3. Noise reduction (e.g., removal of punctuation)\n4. Stemmin"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2607ecf6-bb01-4aa9-8f1c-713d0b6cb8d0"}}},{"cell_type":"markdown","source":["#### 1. Load Data"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6fef7f24-305e-426a-b827-6ec91dca263a"}}},{"cell_type":"code","source":["import pandas as pd\nimport numpy as np\n# File location and type\nfile_location = \"/FileStore/tables/additional.csv\"\nfile_type = \"csv\"\n\n# CSV options\ninfer_schema = \"false\"\nfirst_row_is_header = \"false\"\ndelimiter = \",\"\n\ndf = spark.read.format(file_type).option(\"inferSchema\", infer_schema).option(\"header\", \"true\").option(\"sep\", delimiter).load(file_location)\n\n\npandasDF_news = df.select('news').toPandas()\npandasDF_target = df.select('target').toPandas()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"065a8ba3-3692-4147-80a6-ca891b28cda9"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["from sklearn.datasets import fetch_20newsgroups\nimport pandas as pd\nimport numpy as np\nimport re\nfrom pyspark.sql import SQLContext\n\ncategories = ['rec.autos', 'rec.sport.baseball', 'comp.graphics', 'comp.sys.mac.hardware', \n              'sci.space', 'sci.crypt', 'talk.politics.guns', 'talk.religion.misc']\nnewsgroup = fetch_20newsgroups(subset='train',categories= categories , shuffle=True, random_state=42)\n\ndf_news = pd.DataFrame(data=newsgroup.data, columns=['news']) \n\ndf_news = df_news.append(pandasDF_news, ignore_index=True)\n\ndf_news = df_news.replace(re.compile(r\"From: \\S*@\\S*\\s?\"),\"\")\ndf_news = df_news.replace(re.compile('\\s+'),\" \")\ndf_news = df_news.replace(re.compile(\"\\'\"),\"\")\n\n#df_news = df_news.dropna()\n\ndf_target = pd.DataFrame(data=newsgroup.target, columns=['target'])\n\ndf_target = df_target.append(pandasDF_target, ignore_index=True)\n#df_target = df_target.dropna()\n\ndf_target['target']=df_target.target.astype('int64')\n\ndf_binary_labels = pd.DataFrame(np.where (df_target < 10, 0, 1), columns=['Binary Label'])\n\nsqlContext = SQLContext(sc)\ndf_newsgroup = sqlContext.createDataFrame(pd.concat([df_news, df_target, df_binary_labels], axis=1))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"76b7b165-7c1a-4f34-a415-2234591295ba"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["#### 2. Pipeline"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f5406831-fd9c-410b-9017-0d161c64d6ea"}}},{"cell_type":"code","source":["from pyspark.ml.feature import RegexTokenizer, StopWordsRemover\nfrom pyspark.ml.feature import Tokenizer, HashingTF, IDF, StringIndexer\nfrom pyspark.ml.classification import RandomForestClassifier\nfrom pyspark.ml.classification import DecisionTreeClassifier\nfrom pyspark.ml.classification import LinearSVC\nfrom pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml import Pipeline\n\n\nregexTokenizer = RegexTokenizer(inputCol=\"news\", outputCol=\"news_words\", pattern=\"\\\\W\")\nadd_stopwords = [\"http\",\"https\",\"amp\",\"rt\",\"t\",\"c\",\"the\",\"subject\",\"re\",'.',',','', 'i i','?','\\'\\'',\"''\",'y','*','out','==','df','e.g.','\\'m','\\[',\"'m\",':', ')', '(','n\\'t', '\\'','``','``','\\'s', 'https://','-'] \nstopwordsRemover = StopWordsRemover(inputCol=\"news_words\", outputCol=\"filtered\").setStopWords(add_stopwords)\nhashingTF = HashingTF(inputCol=\"filtered\", outputCol=\"rawFeatures\", numFeatures=10000)\nidf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\", minDocFreq=5) #minDocFreq: remove sparse terms\nstring_indexer = StringIndexer(inputCol = \"target\", outputCol = \"target_indexed\")\n\npipeline = Pipeline(stages=[regexTokenizer, stopwordsRemover, hashingTF, idf, string_indexer])\npipelineFit = pipeline.fit(df_newsgroup)\n\ndataset = pipelineFit.transform(df_newsgroup)\n(trainingData, testData) = dataset.randomSplit([0.7, 0.3], seed = 100)\n#lr = LogisticRegression(maxIter=20, regParam=0.3, elasticNetParam=0)\nrf = RandomForestClassifier(featuresCol=idf.getOutputCol(), labelCol=string_indexer.getOutputCol(), maxDepth=10)\nrf_mod = rf.fit(trainingData)\n#lrModel = lr.fit(trainingData)\n#predictions = lrModel.transform(testData)\npredictions = rf_mod.transform(testData)\n\n# evaluator = MulticlassClassificationEvaluator(labelCol=\"target_indexed\", predictionCol=\"prediction\")\n# evaluator.evaluate(predictions)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ad0fc6b2-eb39-4fb5-a34b-5b95ab291724"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["#### 3. Evaluate ML Model"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8ceb0b67-d451-492d-8e4b-158003aa5a9a"}}},{"cell_type":"code","source":["from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n\nevaluator = MulticlassClassificationEvaluator(labelCol=\"target_indexed\", predictionCol=\"prediction\")\nevaluator.evaluate(predictions)\n\naccuracy = evaluator.evaluate(predictions)\nprint(\"Accuracy = %s\" % (accuracy))\nprint(\"Test Error = %s\" % (1.0 - accuracy))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"41257130-38d7-4cfa-93cf-9817087f8e6f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Accuracy = 0.7032946941465295\nTest Error = 0.29670530585347055\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Accuracy = 0.7032946941465295\nTest Error = 0.29670530585347055\n"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["print (\"Accuracy: \" + str (evaluator.evaluate(predictions, {evaluator.metricName: \"accuracy\"})) )\nprint (\"weightedPrecision: \" + str (evaluator.evaluate(predictions, {evaluator.metricName: \"weightedPrecision\"})) )\nprint (\"weightedRecall: \" + str (evaluator.evaluate(predictions, {evaluator.metricName: \"weightedRecall\"}))  )\nprint (\"weightedTruePositiveRate: \" + str (evaluator.evaluate(predictions, {evaluator.metricName: \"weightedTruePositiveRate\"})) )\nprint (\"weightedFalsePositiveRate: \" + str (evaluator.evaluate(predictions, {evaluator.metricName: \"weightedFalsePositiveRate\"})) )\nprint (\"weightedFMeasure: \" + str (evaluator.evaluate(predictions, {evaluator.metricName: \"weightedFMeasure\"})) )\nprint (\"truePositiveRateByLabel: \" + str (evaluator.evaluate(predictions, {evaluator.metricName: \"truePositiveRateByLabel\"})))\nprint (\"falsePositiveRateByLabel: \" + str (evaluator.evaluate(predictions, {evaluator.metricName: \"falsePositiveRateByLabel\"})) )\nprint (\"precisionByLabel: \" + str (evaluator.evaluate(predictions, {evaluator.metricName: \"precisionByLabel\"})) )\nprint (\"recallByLabel: \" + str (evaluator.evaluate(predictions, {evaluator.metricName: \"recallByLabel\"})) )\nprint (\"fMeasureByLabel: \" + str (evaluator.evaluate(predictions, {evaluator.metricName: \"fMeasureByLabel\"})) )\nprint (\"hammingLoss: \" + str (evaluator.evaluate(predictions, {evaluator.metricName: \"hammingLoss\"})) )"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9cd00106-0645-4a7f-af16-ecbb11187143"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Accuracy: 0.714792899408284\nweightedPrecision: 0.7482196872419422\nweightedRecall: 0.714792899408284\nweightedTruePositiveRate: 0.714792899408284\nweightedFalsePositiveRate: 0.04777471565434986\nweightedFMeasure: 0.7032946941465295\ntruePositiveRateByLabel: 0.909375\nfalsePositiveRateByLabel: 0.1437956204379562\nprecisionByLabel: 0.5963114754098361\nrecallByLabel: 0.909375\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Accuracy: 0.714792899408284\nweightedPrecision: 0.7482196872419422\nweightedRecall: 0.714792899408284\nweightedTruePositiveRate: 0.714792899408284\nweightedFalsePositiveRate: 0.04777471565434986\nweightedFMeasure: 0.7032946941465295\ntruePositiveRateByLabel: 0.909375\nfalsePositiveRateByLabel: 0.1437956204379562\nprecisionByLabel: 0.5963114754098361\nrecallByLabel: 0.909375\n"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["#### 4. Parameter tuning"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0b5076f5-04d6-456b-bb50-e8c42f26d850"}}},{"cell_type":"code","source":["from pyspark.ml.tuning import ParamGridBuilder\nfrom pyspark.ml.tuning import CrossValidator\n\ntrainingData1 = trainingData.drop(\"news_words\",\"news_tf\",\"news_tfidf\",\"rawPrediction\",\"probability\",\"prediction\",\"filtered\",\"rawFeatures\",\"CrossValidator_2b30ebf36fbb_rand\")\ntestData1 = testData.drop(\"news_words\",\"news_tf\",\"news_tfidf\",\"rawPrediction\",\"probability\",\"prediction\",\"filtered\",\"rawFeatures\",\"CrossValidator_2b30ebf36fbb_rand\")\n\n\ntrainingData1.show(5)\n\n#grid for randomforest\ngrid = (ParamGridBuilder().baseOn([evaluator.metricName, 'precision']).addGrid(rf.maxDepth, [10, 20]).build())\n\n\n# Instanciation of a CrossValidator\ncv = CrossValidator(estimator=rf, estimatorParamMaps=grid, evaluator=evaluator, numFolds=3)\n\n# Transform the data and train the classifier on the training set\ncv_model = cv.fit(trainingData1)\n\n# Transform the data and perform predictions on the test set\ndf_test_pred1 = cv_model.transform(testData1)\n\n# Evaluate the predictions done on the test set\nevaluator.evaluate(df_test_pred1)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6ab37513-45ba-49c6-be34-5229cf7281fd"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n\u001B[0;32m<command-454663714469487>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mpyspark\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mml\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtuning\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mCrossValidator\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 4\u001B[0;31m \u001B[0mtrainingData1\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtrainingData\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdrop\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"news_words\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\"news_tf\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\"news_tfidf\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\"rawPrediction\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\"probability\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\"prediction\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\"filtered\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\"rawFeatures\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\"CrossValidator_2b30ebf36fbb_rand\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      5\u001B[0m \u001B[0mtestData1\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtestData\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdrop\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"news_words\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\"news_tf\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\"news_tfidf\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\"rawPrediction\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\"probability\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\"prediction\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\"filtered\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\"rawFeatures\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\"CrossValidator_2b30ebf36fbb_rand\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;31mNameError\u001B[0m: name 'trainingData' is not defined","errorSummary":"<span class='ansi-red-fg'>NameError</span>: name 'trainingData' is not defined","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":["\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n\u001B[0;32m<command-454663714469487>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mpyspark\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mml\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtuning\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mCrossValidator\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 4\u001B[0;31m \u001B[0mtrainingData1\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtrainingData\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdrop\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"news_words\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\"news_tf\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\"news_tfidf\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\"rawPrediction\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\"probability\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\"prediction\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\"filtered\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\"rawFeatures\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\"CrossValidator_2b30ebf36fbb_rand\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      5\u001B[0m \u001B[0mtestData1\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtestData\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdrop\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"news_words\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\"news_tf\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\"news_tfidf\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\"rawPrediction\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\"probability\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\"prediction\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\"filtered\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\"rawFeatures\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\"CrossValidator_2b30ebf36fbb_rand\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;31mNameError\u001B[0m: name 'trainingData' is not defined"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["print (\"Accuracy: \" + str (evaluator.evaluate(predictions, {evaluator.metricName: \"accuracy\"})) )\nprint (\"weightedPrecision: \" + str (evaluator.evaluate(predictions, {evaluator.metricName: \"weightedPrecision\"})) )\nprint (\"weightedRecall: \" + str (evaluator.evaluate(predictions, {evaluator.metricName: \"weightedRecall\"}))  )\nprint (\"weightedTruePositiveRate: \" + str (evaluator.evaluate(predictions, {evaluator.metricName: \"weightedTruePositiveRate\"})) )\nprint (\"weightedFalsePositiveRate: \" + str (evaluator.evaluate(predictions, {evaluator.metricName: \"weightedFalsePositiveRate\"})) )\nprint (\"weightedFMeasure: \" + str (evaluator.evaluate(predictions, {evaluator.metricName: \"weightedFMeasure\"})) )\nprint (\"truePositiveRateByLabel: \" + str (evaluator.evaluate(predictions, {evaluator.metricName: \"truePositiveRateByLabel\"})))\nprint (\"falsePositiveRateByLabel: \" + str (evaluator.evaluate(predictions, {evaluator.metricName: \"falsePositiveRateByLabel\"})) )\nprint (\"precisionByLabel: \" + str (evaluator.evaluate(predictions, {evaluator.metricName: \"precisionByLabel\"})) )\nprint (\"recallByLabel: \" + str (evaluator.evaluate(predictions, {evaluator.metricName: \"recallByLabel\"})) )\nprint (\"fMeasureByLabel: \" + str (evaluator.evaluate(predictions, {evaluator.metricName: \"fMeasureByLabel\"})) )\nprint (\"hammingLoss: \" + str (evaluator.evaluate(predictions, {evaluator.metricName: \"hammingLoss\"})) )"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7fd313b5-0cea-4f7c-9fa9-90b6f69c579f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"ENSF 612 Term Proj  after tunning origin+additional","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":454663714469474}},"nbformat":4,"nbformat_minor":0}
